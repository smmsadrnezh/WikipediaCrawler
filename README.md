This is a simple web crawler for persian wikipedia based on scrapy and beautifulsoup.

How to run
=========

This plugin is based on [Scrapy](#). So install these packages with pip.

  * scrapy
  * beautifulsoup
  * requests
  * scipy
  * numpy
  * elasticsearch

How to use
=========

`service elasticsearch start`

`python3.5 start.py` 

TODO
=========

Crawl:

1. Graph

2. Frontier Queue Prioritization

3. Mutual Information

4. Saving Clusters to Elastisearch

5. Progress Bar for K-means

6. Printing Elasticsearch Cluster Addresses

7. Finding best K with maximum L

8. NumPy Sparse Method
 