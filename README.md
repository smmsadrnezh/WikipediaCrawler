This is a simple web crawler for persian wikipedia based on scrapy and beautifulsoup.

How to run
=========

This plugin is based on [Scrapy](#). So install these packages with pip.

  * scrapy
  * beautifulsoup
  * requests
  * scipy
  * numpy
  * elasticsearch

How to use
=========

`scrapy crawl wikipedia 2>logs`

TODO
=========

Crawl:

1. 1009

2. 1009 (Progress bar)

3. 1009 (Manual Configuration)

4. Graph

5. Frontier Queue Prioritization

6. Create Vectors

7. Connecting K from input to K-means

8. Mutual Information

9. Saving Clusters to Elastisearch

10. Progress Bar for K-means

11. Printing Elasticsearch Cluster Addresses

12. Finding best K with maximum L